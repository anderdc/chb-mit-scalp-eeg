{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "097036e0-757d-4d49-87cf-cdf7e8997c8f",
   "metadata": {},
   "source": [
    "# Support Vector Machine\n",
    "I have finally reached a point in the project where models can be trained using the data pipeline I've created. To start, I am using a support vector machine algorithm. It is known for doing exceptionally well in binary classification and when the feature to sample ratio of the data is relatively high.\n",
    "\n",
    "I dropped many (possibly useful) columns when processing the data because not all recording use the same channels, this leads to major discrepancies. I think if performance is horrendously abysmal bringing those columns back in elegantly will be a priority. \n",
    "\n",
    "It took a while to get to this point, so I want to shout out some of the things I learned/did to get here: spectral entropy, PSD, low pass filtering, time-series data segmentation, band power, tons of data extraction/analysis/preprocessing, time/frequency domain feature extraction, data labeling\n",
    "\n",
    "### Goals \n",
    "- refresh myself on the basic ML train, test, analyze workflow\n",
    "- gain insight on the performance of an SVM using the data, do some hyperparameter tuning\n",
    "### Notes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d4110999-a030-44b5-b566-bf6cce903e23",
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "import extraction\n",
    "from extraction.LT import LTPipeline\n",
    "importlib.reload(extraction.LT) # bc I keep updating LTPipeine, this ensures the ipynb cache updates\n",
    "from extraction.tools import get_all_edf_files_for_patient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "882af79a-d8c4-4922-806a-08651337a3b6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[37m2025-07-02 20:34:30,205 - INFO - 117 total file(s) in pipeline!\u001b[0m\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "LTPipeline.run.<locals>.signal_handler() missing 1 required positional argument: 'frame'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m~/github-repos/chb-mit-scalp-eeg/extraction/LT.py:100\u001b[39m, in \u001b[36mrun\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m     98\u001b[39m X_test = pd.DataFrame(X_test_scaled, columns=X_test.columns, index=X_test.index)\n\u001b[32m--> \u001b[39m\u001b[32m100\u001b[39m # assign to object for easily grabbing values again\n\u001b[32m    101\u001b[39m self.X_train, self.X_test, self.y_train, self.y_test = X_train, X_test, y_train, y_test\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/lib/python3.11/concurrent/futures/_base.py:243\u001b[39m, in \u001b[36mas_completed\u001b[39m\u001b[34m(fs, timeout)\u001b[39m\n\u001b[32m    239\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTimeoutError\u001b[39;00m(\n\u001b[32m    240\u001b[39m                 \u001b[33m'\u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[33m (of \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[33m) futures unfinished\u001b[39m\u001b[33m'\u001b[39m % (\n\u001b[32m    241\u001b[39m                 \u001b[38;5;28mlen\u001b[39m(pending), total_futures))\n\u001b[32m--> \u001b[39m\u001b[32m243\u001b[39m \u001b[43mwaiter\u001b[49m\u001b[43m.\u001b[49m\u001b[43mevent\u001b[49m\u001b[43m.\u001b[49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mwait_timeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    245\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m waiter.lock:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/lib/python3.11/threading.py:629\u001b[39m, in \u001b[36mEvent.wait\u001b[39m\u001b[34m(self, timeout)\u001b[39m\n\u001b[32m    628\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m signaled:\n\u001b[32m--> \u001b[39m\u001b[32m629\u001b[39m     signaled = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_cond\u001b[49m\u001b[43m.\u001b[49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    630\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m signaled\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/lib/python3.11/threading.py:327\u001b[39m, in \u001b[36mCondition.wait\u001b[39m\u001b[34m(self, timeout)\u001b[39m\n\u001b[32m    326\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m327\u001b[39m     \u001b[43mwaiter\u001b[49m\u001b[43m.\u001b[49m\u001b[43macquire\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    328\u001b[39m     gotit = \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[31mTypeError\u001b[39m: LTPipeline.run.<locals>.signal_handler() missing 1 required positional argument: 'frame'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 9\u001b[39m\n\u001b[32m      7\u001b[39m \u001b[38;5;66;03m# print(files)\u001b[39;00m\n\u001b[32m      8\u001b[39m pipeline = LTPipeline(files)\n\u001b[32m----> \u001b[39m\u001b[32m9\u001b[39m X_train, X_test, y_train, y_test = \u001b[43mpipeline\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtrain_test_split\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalidation_patient_id\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mchb15\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     11\u001b[39m \u001b[38;5;66;03m# TODO: you are here. testing the multithreaded file processing, and whether cancelling it can cancel the child threads that were spawned,\u001b[39;00m\n\u001b[32m     12\u001b[39m \u001b[38;5;66;03m# then you can start looking into model fitting and such\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/github-repos/chb-mit-scalp-eeg/extraction/LT.py:158\u001b[39m, in \u001b[36mtrain_test_split\u001b[39m\u001b[34m(self, validation_patient_id)\u001b[39m\n\u001b[32m    156\u001b[39m patient_id, df = result\n\u001b[32m    157\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m patient_id \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m patient_data:\n\u001b[32m--> \u001b[39m\u001b[32m158\u001b[39m     patient_data[patient_id] = df\n\u001b[32m    159\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    160\u001b[39m     patient_data[patient_id] = pd.concat([patient_data[patient_id], df], axis=\u001b[32m0\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/github-repos/chb-mit-scalp-eeg/extraction/LT.py:93\u001b[39m, in \u001b[36mrun\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m     91\u001b[39m \u001b[38;5;66;03m# standardize the data, mean=0, std=1\u001b[39;00m\n\u001b[32m     92\u001b[39m scaler = StandardScaler()\n\u001b[32m---> \u001b[39m\u001b[32m93\u001b[39m X_train_scaled = scaler.fit_transform(X_train)\n\u001b[32m     94\u001b[39m X_test_scaled = scaler.transform(X_test)   \u001b[38;5;66;03m# only fit train data to avoid data leakage\u001b[39;00m\n\u001b[32m     96\u001b[39m \u001b[38;5;66;03m# convert scaled data to dataframes\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/lib/python3.11/concurrent/futures/_base.py:647\u001b[39m, in \u001b[36mExecutor.__exit__\u001b[39m\u001b[34m(self, exc_type, exc_val, exc_tb)\u001b[39m\n\u001b[32m    646\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__exit__\u001b[39m(\u001b[38;5;28mself\u001b[39m, exc_type, exc_val, exc_tb):\n\u001b[32m--> \u001b[39m\u001b[32m647\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mshutdown\u001b[49m\u001b[43m(\u001b[49m\u001b[43mwait\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m    648\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/lib/python3.11/concurrent/futures/thread.py:235\u001b[39m, in \u001b[36mThreadPoolExecutor.shutdown\u001b[39m\u001b[34m(self, wait, cancel_futures)\u001b[39m\n\u001b[32m    233\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m wait:\n\u001b[32m    234\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m._threads:\n\u001b[32m--> \u001b[39m\u001b[32m235\u001b[39m         \u001b[43mt\u001b[49m\u001b[43m.\u001b[49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/lib/python3.11/threading.py:1119\u001b[39m, in \u001b[36mThread.join\u001b[39m\u001b[34m(self, timeout)\u001b[39m\n\u001b[32m   1116\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mcannot join current thread\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m   1118\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1119\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_wait_for_tstate_lock\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1120\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1121\u001b[39m     \u001b[38;5;66;03m# the behavior of a negative timeout isn't documented, but\u001b[39;00m\n\u001b[32m   1122\u001b[39m     \u001b[38;5;66;03m# historically .join(timeout=x) for x<0 has acted as if timeout=0\u001b[39;00m\n\u001b[32m   1123\u001b[39m     \u001b[38;5;28mself\u001b[39m._wait_for_tstate_lock(timeout=\u001b[38;5;28mmax\u001b[39m(timeout, \u001b[32m0\u001b[39m))\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/lib/python3.11/threading.py:1139\u001b[39m, in \u001b[36mThread._wait_for_tstate_lock\u001b[39m\u001b[34m(self, block, timeout)\u001b[39m\n\u001b[32m   1136\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[32m   1138\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1139\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mlock\u001b[49m\u001b[43m.\u001b[49m\u001b[43macquire\u001b[49m\u001b[43m(\u001b[49m\u001b[43mblock\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[32m   1140\u001b[39m         lock.release()\n\u001b[32m   1141\u001b[39m         \u001b[38;5;28mself\u001b[39m._stop()\n",
      "\u001b[31mTypeError\u001b[39m: LTPipeline.run.<locals>.signal_handler() missing 1 required positional argument: 'frame'"
     ]
    }
   ],
   "source": [
    "# pipeline\n",
    "files = get_all_edf_files_for_patient('chb01')\n",
    "files.extend(get_all_edf_files_for_patient('chb02'))\n",
    "files.extend(get_all_edf_files_for_patient('chb03'))\n",
    "files.extend(['chb15_06.edf'])   # manually add one file that will be validation data\n",
    "\n",
    "# print(files)\n",
    "pipeline = LTPipeline(files, verbose=True)\n",
    "X_train, X_test, y_train, y_test = pipeline.train_test_split(validation_patient_id='chb15')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7ee508c-f0d3-4f3e-906e-e33734e2c314",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SVC(\n",
    "    C=1.0,\n",
    "    tol=0.01,\n",
    "    kernel=\"rbf\",\n",
    "    class_weight=\"balanced\",\n",
    "    random_state=27\n",
    ")\n",
    "'''\n",
    "C - Regularization parameter. The strength of the regularization is inversely proportional to C.\n",
    "tol - Tolerance for stopping criterion.\n",
    "class_weight - The “balanced” mode uses the values of y to automatically adjust weights inversely proportional to class frequencies\n",
    "in the input data. i.e. higher frequency classes have lower weights (for calculating loss), and vice versa\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52ce6d8f-3538-408b-b922-5d65333a3a5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_train_pca = rf.predict(X_train_pca)\n",
    "acc = accuracy_score(y_train_new, y_pred_train_pca, normalize=True)\n",
    "print(f'Accuracy for the train data is {acc*100:.2f}%')\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
