{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "097036e0-757d-4d49-87cf-cdf7e8997c8f",
   "metadata": {},
   "source": [
    "# Support Vector Machine\n",
    "I have finally reached a point in the project where models can be trained using the data pipeline I've created. To start, I am using a support vector machine algorithm. It is known for doing exceptionally well in binary classification and when the feature to sample ratio of the data is relatively high.\n",
    "\n",
    "I dropped many (possibly useful) columns when processing the data because not all recording use the same channels, this leads to major discrepancies. I think if performance is horrendously abysmal bringing those columns back in elegantly will be a priority. \n",
    "\n",
    "It took a while to get to this point, so I want to shout out some of the things I learned/did to get here: spectral entropy, PSD, low pass filtering, time-series data segmentation, band power, tons of data extraction/analysis/preprocessing, time/frequency domain feature extraction, data labeling\n",
    "\n",
    "### Goals \n",
    "- refresh myself on the basic ML train, test, analyze workflow\n",
    "- gain insight on the performance of an SVM using the data, do some hyperparameter tuning\n",
    "### Notes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d4110999-a030-44b5-b566-bf6cce903e23",
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "import extraction\n",
    "from extraction.LT import LTPipeline\n",
    "importlib.reload(extraction.LT) # bc I keep updating LTPipeine, this ensures the ipynb cache updates\n",
    "from extraction.tools import get_all_edf_files_for_patient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "882af79a-d8c4-4922-806a-08651337a3b6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[37m2025-07-02 03:49:28,581 - INFO - 117 total file(s) in pipeline!\u001b[0m\n",
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# pipeline\n",
    "files = get_all_edf_files_for_patient('chb01')\n",
    "files.extend(get_all_edf_files_for_patient('chb02'))\n",
    "files.extend(get_all_edf_files_for_patient('chb03'))\n",
    "files.extend(['chb15_06.edf'])   # manually add one file that will be validation data\n",
    "\n",
    "# print(files)\n",
    "pipeline = LTPipeline(files)\n",
    "X_train, X_test, y_train, y_test = pipeline.train_test_split(validation_patient_id='chb15')\n",
    "\n",
    "# TODO: you are here. testing the multithreaded file processing, and whether cancelling it can cancel the child threads that were spawned,\n",
    "# then you can start looking into model fitting and such"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7ee508c-f0d3-4f3e-906e-e33734e2c314",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SVC(\n",
    "    C=1.0,      # Regularization parameter. The strength of the regularization is inversely proportional to C.\n",
    "    tol=0.01,   # Tolerance for stopping criterion.\n",
    "    kernel=\"rbf\",\n",
    "    class_weight=\"balanced\", # The “balanced” mode uses the values of y to automatically adjust weights inversely proportional to class frequencies in the input data\n",
    "    random_state=27\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52ce6d8f-3538-408b-b922-5d65333a3a5a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
